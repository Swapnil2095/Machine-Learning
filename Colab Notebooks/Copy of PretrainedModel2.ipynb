{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of PretrainedModel2.ipynb","version":"0.3.2","provenance":[{"file_id":"1CkhRzzuXTGAETNE8rqSXFqyjt2zLsDiS","timestamp":1545637705983}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"fSKoLIGp3YMO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"4a7d5583-ffe7-46c7-e719-b98acc8f1b04","executionInfo":{"status":"ok","timestamp":1545637694188,"user_tz":-330,"elapsed":38275,"user":{"displayName":"Swapnil","photoUrl":"https://lh3.googleusercontent.com/-linSjZVe6h4/AAAAAAAAAAI/AAAAAAAAAPs/tU6VXuQJoWE/s64/photo.jpg","userId":"07728357249993231372"}}},"cell_type":"code","source":["# http://pytorch.org/\n","from os.path import exists\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n","accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"],"execution_count":1,"outputs":[{"output_type":"stream","text":["tcmalloc: large alloc 1073750016 bytes == 0x58a12000 @  0x7f1e8ffc42a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"],"name":"stdout"}]},{"metadata":{"id":"OgKa-5D9-PNo","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import os"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KzAtrLUk3q6X","colab_type":"code","colab":{}},"cell_type":"code","source":["!wget -cq https://github.com/udacity/pytorch_challenge/raw/master/cat_to_name.json\n","\n","!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n","\n","!unzip -qq flower_data.zip"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zIweCPyJ-gp0","colab_type":"code","colab":{}},"cell_type":"code","source":["# create train and test loader\n","data_dir = 'flower_data'\n","\n","from torchvision import datasets, transforms\n","\n","# number of subprocesses to use for data loading\n","num_workers = 0\n","# how many samples per batch to load\n","batch_size = 20\n","# percentage of training set to use as validation\n","valid_size = 0.2\n","\n","# convert data to torch.FloatTensor\n","transform_train = transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","\n","transform_valid = transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ])\n","\n","test_transforms = transforms.Compose([transforms.Resize(255),\n","                                      transforms.CenterCrop(224),\n","                                      transforms.ToTensor()])\n","\n","#data set\n","train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n","\n","valid_data = datasets.ImageFolder(data_dir + '/valid', transform=valid_transforms)\n","\n","test_data = datasets.ImageFolder(data_dir + '/valid', transform=test_transforms)\n","\n","# obtain training indices that will be used for validation\n","num_train = len(train_data)\n","print(num_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7rMwHndzDs42","colab_type":"code","colab":{}},"cell_type":"code","source":["# index of num of train\n","indices = list(range(num_train))\n","#random the index\n","np.random.shuffle(indices)\n","split = int(np.floor(valid_size * num_train))\n","# divied into two part\n","train_idx, valid_idx = indices[split:], indices[:split]\n","\n","# define the sampler\n","train_sampler = SubsetRandomSampler(train_idx)\n","valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","# prepare loaders\n","train_loader = torch.utils.data.DataLoader(\n","    train_data,batch_size=batch_size,\n","    sampler = train_sampler,num_workers = num_workers)\n","\n","valid_loader = torch.utils.data.DataLoader(\n","    valid_data,batch_size=batch_size,\n","    sampler = valid_sampler,num_workers = num_workers)\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_data,batch_size=batch_size,num_workers = num_workers)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vPtyhxYGGDgo","colab_type":"code","colab":{}},"cell_type":"code","source":["flowers_class = {\"21\": \"fire lily\", \"3\": \"canterbury bells\", \"45\": \"bolero deep blue\", \"1\": \"pink primrose\", \"34\": \"mexican aster\", \"27\": \"prince of wales feathers\", \"7\": \"moon orchid\", \"16\": \"globe-flower\", \"25\": \"grape hyacinth\", \"26\": \"corn poppy\", \"79\": \"toad lily\", \"39\": \"siam tulip\", \"24\": \"red ginger\", \"67\": \"spring crocus\", \"35\": \"alpine sea holly\", \"32\": \"garden phlox\", \"10\": \"globe thistle\", \"6\": \"tiger lily\", \"93\": \"ball moss\", \"33\": \"love in the mist\", \"9\": \"monkshood\", \"102\": \"blackberry lily\", \"14\": \"spear thistle\", \"19\": \"balloon flower\", \"100\": \"blanket flower\", \"13\": \"king protea\", \"49\": \"oxeye daisy\", \"15\": \"yellow iris\", \"61\": \"cautleya spicata\", \"31\": \"carnation\", \"64\": \"silverbush\", \"68\": \"bearded iris\", \"63\": \"black-eyed susan\", \"69\": \"windflower\", \"62\": \"japanese anemone\", \"20\": \"giant white arum lily\", \"38\": \"great masterwort\", \"4\": \"sweet pea\", \"86\": \"tree mallow\", \"101\": \"trumpet creeper\", \"42\": \"daffodil\", \"22\": \"pincushion flower\", \"2\": \"hard-leaved pocket orchid\", \"54\": \"sunflower\", \"66\": \"osteospermum\", \"70\": \"tree poppy\", \"85\": \"desert-rose\", \"99\": \"bromelia\", \"87\": \"magnolia\", \"5\": \"english marigold\", \"92\": \"bee balm\", \"28\": \"stemless gentian\", \"97\": \"mallow\", \"57\": \"gaura\", \"40\": \"lenten rose\", \"47\": \"marigold\", \"59\": \"orange dahlia\", \"48\": \"buttercup\", \"55\": \"pelargonium\", \"36\": \"ruby-lipped cattleya\", \"91\": \"hippeastrum\", \"29\": \"artichoke\", \"71\": \"gazania\", \"90\": \"canna lily\", \"18\": \"peruvian lily\", \"98\": \"mexican petunia\", \"8\": \"bird of paradise\", \"30\": \"sweet william\", \"17\": \"purple coneflower\", \"52\": \"wild pansy\", \"84\": \"columbine\", \"12\": \"colt's foot\", \"11\": \"snapdragon\", \"96\": \"camellia\", \"23\": \"fritillary\", \"50\": \"common dandelion\", \"44\": \"poinsettia\", \"53\": \"primula\", \"72\": \"azalea\", \"65\": \"californian poppy\", \"80\": \"anthurium\", \"76\": \"morning glory\", \"37\": \"cape flower\", \"56\": \"bishop of llandaff\", \"60\": \"pink-yellow dahlia\", \"82\": \"clematis\", \"58\": \"geranium\", \"75\": \"thorn apple\", \"41\": \"barbeton daisy\", \"95\": \"bougainvillea\", \"43\": \"sword lily\", \"83\": \"hibiscus\", \"78\": \"lotus lotus\", \"88\": \"cyclamen\", \"94\": \"foxglove\", \"81\": \"frangipani\", \"74\": \"rose\", \"89\": \"watercress\", \"73\": \"water lily\", \"46\": \"wallflower\", \"77\": \"passion flower\", \"51\": \"petunia\"}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-1bthsJE7oDH","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","    \n","# obtain one batch of training images\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","images = images.numpy()\n","\n","# plot the images in the batch, along with the corresponding labels\n","fig = plt.figure(figsize=(25, 4))\n","for idx in np.arange(8):\n","    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n","    img = images[idx] / 2 + 0.5\n","    plt.imshow(np.transpose(img, (1, 2, 0)))\n","    #ax.imshow(np.squeeze(images[idx]), cmap='gray')\n","    # print out the correct label for each image\n","    # .item() gets the value contained in a Tensor\n","    # ax.set_title(str(labels[idx].item()))\n","    s = str(labels[idx].item())\n","    ax.set_title(flowers_class[s])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ay_A4OrwB1xi","colab_type":"code","colab":{}},"cell_type":"code","source":["# load a pretrained model\n","model = models.densenet169(pretrained = True)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","model.to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xcCs3pj4Hrt3","colab_type":"code","colab":{}},"cell_type":"code","source":["# Freeze the parameters\n","for param in model.parameters():\n","  param.required_grad = False"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aU-Sbm9sHy2L","colab_type":"code","colab":{}},"cell_type":"code","source":["from collections import OrderedDict\n","from torch import nn\n","classifier = nn.Sequential(OrderedDict([\n","                ('fc1', nn.Linear(1024, 500)),\n","                ('relu', nn.ReLU()),\n","                ('fc2', nn.Linear(500, 2)),\n","                ('output', nn.LogSoftmax(dim=1))\n","                ]))\n","\n","# replace the classifer\n","model.classifier = classifier\n","# check the classifier\n","print(model.classifier)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9O_057N6H2cR","colab_type":"code","colab":{}},"cell_type":"code","source":["from torch import optim\n","from torch.optim import lr_scheduler\n","# set cretrion and optimizer\n","criterion = nn.CrossEntropyLoss()\n","# Observe that all parameters are being optimized\n","optimizer = optim.SGD(model.parameters(), lr=0.03, momentum=0.9)\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vg6hYbFfI4Yb","colab_type":"code","colab":{}},"cell_type":"code","source":["# Train\n","# number of epochs to train the model\n","n_epochs = 20\n","\n","valid_loss_min = np.Inf\n","\n","train_loss_data, valid_loss_data = [],[] \n","\n","for epoch in range(n_epochs):\n","  train_loss = 0\n","  test_loss = 0\n","  accuracy = 0\n","  \n","  ###############\n","  # Train Model #\n","  ###############\n","  model.train()\n","  # step scheduler\n","  scheduler.step()\n","  \n","  for images, labels in train_loader:\n","    # move to cuda\n","    images, labels = images.to(device), labels.to(device)\n","    #zero gradient\n","    optimizer.zero_grad()\n","    # Forward pass\n","    output = model(images)\n","    #calculate loss\n","    loss = criterion(output,labels)\n","    # backward pass\n","    loss.backward()\n","    # perform a single optimization step (parameters update)\n","    optimizer.step()\n","    # update train loss\n","    train_loss += loss.item() * images.size(0)\n","  \n","  \n","  ######################\n","  # Validate the model #\n","  ######################\n","  model.eval()\n","  for images, labels in valid_loader:\n","    # move to cuda\n","    images, labels = images.to(device), labels.to(device)\n","    # Forward pass\n","    log_ps = model(images)\n","    #calculate loss\n","    loss = criterion(log_ps,labels)\n","    # update train loss\n","    valid_loss += loss.item() * images.size(0)\n","    # calculate accuracy\n","    ps = torch.exp(log_ps)\n","    top_p, top_class = ps.topk(1, dim=1)\n","    equals = top_class == labels.view(*top_class.shape)\n","    accuracy += torch.mean(equals.type(torch.FloatTensor))\n","  \n","  \n","  # Calculate the average loss in one epoch\n","  train_loss = train_loss/len(train_loader.dataset)\n","  valid_loss = valid_loss/len(valid_loader.dataset)\n","  # save the loss in an array\n","  train_loss_data.append(train_loss * 100)\n","  valid_loss_data.append(valid_loss * 100)\n","  \n","  # print the loss\n","  print(\"Epoch {}/{}\".format(epoch+1,n_epochs),\"\\tTrain loss:{:.4f}\".format(train_loss),\n","       \"\\t Valid Loss:{:.4f}\".format(valid_loss),\"\\tAcceuracy:{:.2f}%\".format(accuracy))\n","  \n","  # save the vodel\n","  if valid_loss <= valid_loss_min:\n","    print('Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...'.format(\n","        valid_loss_min,\n","        valid_loss))\n","    torch.save(model.state_dict(), 'model_cifar.pt')\n","    valid_loss_min = valid_loss"],"execution_count":0,"outputs":[]},{"metadata":{"id":"384YlWb5I_tV","colab_type":"code","colab":{}},"cell_type":"code","source":["model.load_state_dict(torch.load(\"model_cifar.pt\"))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ksEJIsCPJB6z","colab_type":"code","colab":{}},"cell_type":"code","source":["# check for overfitting\n","plt.plot(train_loss_data, label = \"taining loss\")\n","plt.plot(valid_loss_data, label = \"validation loss\")\n","plt.legend(frameon = False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UFpwCwTVJEGr","colab_type":"code","colab":{}},"cell_type":"code","source":["# track test loss\n","test_loss = 0.0\n","class_correct = list(0. for i in range(10))\n","class_total = list(0. for i in range(10))\n","\n","with torch.no_grad():\n","  model.eval()\n","  # iterate over test data\n","  for data, target in test_loader:\n","      # move tensors to GPU if CUDA is available\n","      data, target = data.to(device), target.to(device)\n","      # forward pass: compute predicted outputs by passing inputs to the model\n","      output = model(data)\n","      # calculate the batch loss\n","      loss = criterion(output, target)\n","      # update test loss \n","      test_loss += loss.item()*data.size(0)\n","      # convert output probabilities to predicted class\n","      _, pred = torch.max(output, 1)    \n","      # compare predictions to true label\n","      correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n","      # calculate test accuracy for each object class\n","      for i in range(batch_size):\n","          label = target.data[i]\n","          class_correct[label] += correct[i].item()\n","          class_total[label] += 1\n","\n","# average test loss\n","test_loss = test_loss/len(test_loader.dataset)\n","print('Test Loss: {:.6f}\\n'.format(test_loss))\n","\n","for i in range(10):\n","    if class_total[i] > 0:\n","        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n","            classes[i], 100 * class_correct[i] / class_total[i],\n","            np.sum(class_correct[i]), np.sum(class_total[i])))\n","    else:\n","        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n","\n","print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n","    100. * np.sum(class_correct) / np.sum(class_total),\n","    np.sum(class_correct), np.sum(class_total)))"],"execution_count":0,"outputs":[]}]}