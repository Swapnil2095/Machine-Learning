{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of 1.flower_species_classification_pytorch.ipynb","version":"0.3.2","provenance":[{"file_id":"1wRwWF34-P86SNlfo7cSuFXCUVxTJBp06","timestamp":1546095269482},{"file_id":"1v1Eu1JKH48YuV4TI9cjLjoO3L2KV8Gt9","timestamp":1545482239440}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"-EtL_cX3L8DD","colab_type":"code","colab":{}},"cell_type":"code","source":["# This is to set up necessary dependencies, and make sure currenyt versions are installed\n","!pip install torch torchvision\n","!pip install Pillow==4.1.1\n","!pip install cv2\n","import PIL\n","import cv2\n","# NOTE: it could be needed to restart the runtime after this step if PIL related errors are encountered later during training"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v3Vpmwvw32N-","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"A4Z1R6MxUzxI","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"DYvtCCAcjXAr","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# Download the data\n","#!wget https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n","#!unzip flower_data.zip\n","# I found it useful and convenient to save the model on Google Drive.\n","# This links the drive to this notebook\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zhEvL_5iL1Ct","colab_type":"code","colab":{}},"cell_type":"code","source":["# Main imports\n","import numpy as np\n","import time\n","import torch\n","from torchvision import datasets, models, transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# Helper Functions\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch import nn, optim\n","from torch.autograd import Variable"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E8EyzGTMdBwz","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","print(os.listdir(\"flower_data\"))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XmhDzcOSzt7m","colab_type":"code","colab":{}},"cell_type":"code","source":["def test_network(net, trainloader):\n","\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","    dataiter = iter(trainloader)\n","    images, labels = dataiter.next()\n","\n","    # Create Variables for the inputs and targets\n","    inputs = Variable(images)\n","    targets = Variable(images)\n","\n","    # Clear the gradients from all Variables\n","    optimizer.zero_grad()\n","\n","    # Forward pass, then backward pass, then update weights\n","    output = net.forward(inputs)\n","    loss = criterion(output, targets)\n","    loss.backward()\n","    optimizer.step()\n","\n","    return True\n","\n","\n","def imshow(image, ax=None, title=None, normalize=True):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    if ax is None:\n","        fig, ax = plt.subplots()\n","    image = image.numpy().transpose((1, 2, 0))\n","\n","    if normalize:\n","        mean = np.array([0.485, 0.456, 0.406])\n","        std = np.array([0.229, 0.224, 0.225])\n","        image = std * image + mean\n","        image = np.clip(image, 0, 1)\n","\n","    ax.imshow(image)\n","    ax.spines['top'].set_visible(False)\n","    ax.spines['right'].set_visible(False)\n","    ax.spines['left'].set_visible(False)\n","    ax.spines['bottom'].set_visible(False)\n","    ax.tick_params(axis='both', length=0)\n","    ax.set_xticklabels('')\n","    ax.set_yticklabels('')\n","\n","    return ax\n","\n","\n","def view_recon(img, recon):\n","    ''' Function for displaying an image (as a PyTorch Tensor) and its\n","        reconstruction also a PyTorch Tensor\n","    '''\n","\n","    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n","    axes[0].imshow(img.numpy().squeeze())\n","    axes[1].imshow(recon.data.numpy().squeeze())\n","    for ax in axes:\n","        ax.axis('off')\n","        ax.set_adjustable('box-forced')\n","\n","def view_classify(img, ps, version=\"MNIST\"):\n","    ''' Function for viewing an image and it's predicted classes.\n","    '''\n","    ps = ps.data.numpy().squeeze()\n","\n","    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n","    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n","    ax1.axis('off')\n","    ax2.barh(np.arange(10), ps)\n","    ax2.set_aspect(0.1)\n","    ax2.set_yticks(np.arange(10))\n","    if version == \"MNIST\":\n","        ax2.set_yticklabels(np.arange(10))\n","    elif version == \"Fashion\":\n","        ax2.set_yticklabels(['T-shirt/top',\n","                            'Trouser',\n","                            'Pullover',\n","                            'Dress',\n","                            'Coat',\n","                            'Sandal',\n","                            'Shirt',\n","                            'Sneaker',\n","                            'Bag',\n","                            'Ankle Boot'], size='small');\n","    ax2.set_title('Class Probability')\n","    ax2.set_xlim(0, 1.1)\n","\n","    plt.tight_layout()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ROu8PClo0dGu","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xa5frUpG0S5g","colab_type":"code","colab":{}},"cell_type":"code","source":["data_dir = 'flower_data'\n","train_dir = data_dir + '/train'\n","valid_dir = data_dir + '/valid'\n","print(os.listdir(data_dir))\n","print(os.listdir(train_dir))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bfdq7Bxx0kit","colab_type":"code","colab":{}},"cell_type":"code","source":["#My transforms for the training and validation sets\n","train_transforms = transforms.Compose([transforms.Resize(255),\n","                                transforms.CenterCrop(224),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize([0.485, 0.456, 0.406],\n","                                                     [0.229, 0.224, 0.225])])\n","\n","test_transforms = transforms.Compose([transforms.Resize(255),\n","                                      transforms.CenterCrop(224),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize([0.485, 0.456, 0.406],\n","                                                           [0.229, 0.224, 0.225])])\n","#Loading the datasets with ImageFolder\n","train_data  = datasets.ImageFolder(train_dir, transform=train_transforms)\n","valid_data  = datasets.ImageFolder(valid_dir, transform=train_transforms)\n","\n","# print out some data stats\n","print('Num training images: ', len(train_data))\n","print('Num test images: ', len(valid_data))\n","\n","#Using the image datasets and the trainforms, define the dataloaders\n","train_loader  = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\n","valid_loader  = torch.utils.data.DataLoader(valid_data, batch_size=16, shuffle=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0Rj-hC-D0t5e","colab_type":"code","colab":{}},"cell_type":"code","source":["# Run this to test your data loader\n","#Visualiza Some Images of any Random Directory-cum-Class\n","FILE_DIR = str(np.random.randint(1,103))\n","print(\"Class Directory: \",FILE_DIR)\n","for file_name in os.listdir(os.path.join(train_dir, FILE_DIR))[1:3]:\n","    img_array = cv2.imread(os.path.join(train_dir, FILE_DIR, file_name))\n","    img_array = cv2.resize(img_array,(224, 224), interpolation = cv2.INTER_CUBIC)\n","    plt.imshow(img_array)\n","    plt.show()\n","    print(img_array.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M935cKw31DYS","colab_type":"code","colab":{}},"cell_type":"code","source":["# check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TbXg-3yf1GiJ","colab_type":"code","colab":{}},"cell_type":"code","source":["import json\n","!ls\n","with open('cat_to_name.json', 'r') as f:\n","  print(f)\n","  cat_to_name = json.load(f)\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"zzK2ahHj1Mpg","colab_type":"code","colab":{}},"cell_type":"code","source":["len(cat_to_name)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JqWyG0SrDiB9","colab_type":"code","colab":{}},"cell_type":"code","source":["cat_to_name"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QtD_vG5ysLUc","colab_type":"code","colab":{}},"cell_type":"code","source":["# I used os.listdir() to maintain the ordering \n","classes = os.listdir(valid_dir)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Yl1_onB0s7V7","colab_type":"code","colab":{}},"cell_type":"code","source":["# Visualize some sample data\n","\n","# obtain one batch of training images\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","images = images.numpy() # convert images to numpy for display\n","\n","# plot the images in the batch, along with the corresponding labels\n","fig = plt.figure(figsize=(25, 4))\n","for idx in np.arange(15):\n","    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n","    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n","    ax.set_title(classes[labels[idx]])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YwfyVYIz1VpB","colab_type":"code","colab":{}},"cell_type":"code","source":["#Built and trained my network\n","model = models.densenet121(pretrained=True)\n","model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x90dm42rxAHf","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use GPU if it's available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# Freeze parameters so we don't backprop through them\n","for param in model.parameters():\n","    param.requires_grad = False\n","    \n","model.classifier = nn.Sequential(nn.Linear(1024, 500),\n","                                 nn.ReLU(),\n","                                 nn.Dropout(0.3),\n","                                 nn.Linear(500, 102),\n","                                 nn.LogSoftmax(dim=1))\n","\n","criterion = nn.NLLLoss()\n","\n","# Only train the classifier parameters, feature parameters are frozen\n","optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n","\n","model.to(device);"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jpetPM2-1YOQ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Define epochs (between 50-200)\n","epochs = 20\n","# initialize tracker for minimum validation loss\n","valid_loss_min = np.Inf # set initial \"min\" to infinity\n","\n","# Some lists to keep track of loss and accuracy during each epoch\n","epoch_list = []\n","train_loss_list = []\n","val_loss_list = []\n","train_acc_list = []\n","val_acc_list = []\n","# Start epochs\n","for epoch in range(epochs):\n","    \n","    #adjust_learning_rate(optimizer, epoch)\n","    \n","    # monitor training loss\n","    train_loss = 0.0\n","    val_loss = 0.0\n","    \n","    ###################\n","    # train the model #\n","    ###################\n","    # Set the training mode ON -> Activate Dropout Layers\n","    model.train() # prepare model for training\n","    # Calculate Accuracy         \n","    correct = 0\n","    total = 0\n","    \n","    # Load Train Images with Labels(Targets)\n","    for data, target in train_loader:\n","        \n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        \n","        # clear the gradients of all optimized variables\n","        optimizer.zero_grad()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        \n","        if type(output) == tuple:\n","            output, _ = output\n","        \n","        # Calculate Training Accuracy \n","        predicted = torch.max(output.data, 1)[1]        \n","        # Total number of labels\n","        total += len(target)\n","        # Total correct predictions\n","        correct += (predicted == target).sum()\n","        \n","        # calculate the loss\n","        loss = criterion(output, target)\n","        # backward pass: compute gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # perform a single optimization step (parameter update)\n","        optimizer.step()\n","        # update running training loss\n","        train_loss += loss.item()*data.size(0)\n","    \n","    # calculate average training loss over an epoch\n","    train_loss = train_loss/len(train_loader.dataset)\n","    \n","    # Avg Accuracy\n","    accuracy = 100 * correct / float(total)\n","    \n","    # Put them in their list\n","    train_acc_list.append(accuracy)\n","    train_loss_list.append(train_loss)\n","    \n","        \n","    # Implement Validation like K-fold Cross-validation \n","    \n","    # Set Evaluation Mode ON -> Turn Off Dropout\n","    model.eval() # Required for Evaluation/Test\n","\n","    # Calculate Test/Validation Accuracy         \n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data, target in valid_loader:\n","\n","\n","            if train_on_gpu:\n","                data, target = data.cuda(), target.cuda()\n","\n","            # Predict Output\n","            output = model(data)\n","            if type(output) == tuple:\n","                output, _ = output\n","\n","            # Calculate Loss\n","            loss = criterion(output, target)\n","            val_loss += loss.item()*data.size(0)\n","            # Get predictions from the maximum value\n","            predicted = torch.max(output.data, 1)[1]\n","\n","            # Total number of labels\n","            total += len(target)\n","\n","            # Total correct predictions\n","            correct += (predicted == target).sum()\n","    \n","    # calculate average training loss and accuracy over an epoch\n","    val_loss = val_loss/len(valid_loader.dataset)\n","    accuracy = 100 * correct/ float(total)\n","    \n","    # Put them in their list\n","    val_acc_list.append(accuracy)\n","    val_loss_list.append(val_loss)\n","    \n","    # Print the Epoch and Training Loss Details with Validation Accuracy   \n","    print('Epoch: {} \\tTraining Loss: {:.4f}\\t Val. acc: {:.2f}%'.format(\n","        epoch+1, \n","        train_loss,\n","        accuracy\n","        ))\n","    # save model if validation loss has decreased\n","    if val_loss <= valid_loss_min:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","        valid_loss_min,\n","        val_loss))\n","        # Save Model State on Checkpoint\n","        torch.save(model.state_dict(), 'model.pt')\n","        valid_loss_min = val_loss\n","    # Move to next epoch\n","    epoch_list.append(epoch + 1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vg2sMnK51dMM","colab_type":"code","colab":{}},"cell_type":"code","source":["model_save_name = 'model.pt'\n","path = F\"/content/gdrive/My Drive/{model_save_name}\" \n","torch.save(model.state_dict(), path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t0D3up5rIKh4","colab_type":"code","colab":{}},"cell_type":"code","source":["model.load_state_dict(torch.load('model.pt'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SXYtSE4OxYKq","colab_type":"code","colab":{}},"cell_type":"code","source":["#Save/Pickle the Model\n","torch.save(model, 'classifier.pth')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L3q7gfz8xY4n","colab_type":"code","colab":{}},"cell_type":"code","source":["# Training / Validation Loss\n","plt.plot(epoch_list,train_loss_list)\n","plt.plot(val_loss_list)\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training/Validation Loss vs Number of Epochs\")\n","plt.legend(['Train', 'Valid'], loc='upper right')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ap-GDFeSxbi7","colab_type":"code","colab":{}},"cell_type":"code","source":["# Train/Valid Accuracy\n","plt.plot(epoch_list,train_acc_list)\n","plt.plot(val_acc_list)\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Training/Validation Accuracy\")\n","plt.title(\"Accuracy vs Number of Epochs\")\n","plt.legend(['Train', 'Valid'], loc='best')\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xymF8HoBxeWW","colab_type":"code","colab":{}},"cell_type":"code","source":["val_acc = sum(val_acc_list[:]).item()/len(val_acc_list)\n","print(\"Validation Accuracy of model = {} %\".format(val_acc))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-UdyUw17xhdv","colab_type":"code","colab":{}},"cell_type":"code","source":["# obtain one batch of test images\n","dataiter = iter(valid_loader)\n","images, labels = dataiter.next()\n","img = images.numpy()\n","\n","# move model inputs to cuda, if GPU available\n","if train_on_gpu:\n","    images = images.cuda()\n","\n","model.eval() # Required for Evaluation/Test\n","# get sample outputs\n","output = model(images)\n","if type(output) == tuple:\n","            output, _ = output\n","# convert output probabilities to predicted class\n","_, preds_tensor = torch.max(output, 1)\n","preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n","\n","# plot the images in the batch, along with predicted and true labels\n","fig = plt.figure(figsize=(20, 5))\n","for idx in np.arange(12):\n","    ax = fig.add_subplot(3, 4, idx+1, xticks=[], yticks=[])\n","    plt.imshow(np.transpose(img[idx], (1, 2, 0)))\n","    ax.set_title(\"Pr: {} Ac: {}\".format(classes[preds[idx]], classes[labels[idx]]),\n","                 color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OtRk_kt6xq2t","colab_type":"code","colab":{}},"cell_type":"code","source":["!git clone https://github.com/GabrielePicco/deep-learning-flower-identifier\n","!pip install airtable\n","import sys\n","sys.path.insert(0, 'deep-learning-flower-identifier')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0M_9Nec1x8S7","colab_type":"code","colab":{}},"cell_type":"code","source":["from test_model_pytorch_facebook_challenge import calc_accuracy\n","calc_accuracy(model, input_image_size=224, use_google_testset=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0H4AFNHxx90L","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_fbHATuVUUpH","colab_type":"code","colab":{}},"cell_type":"code","source":["model.cpu()\n","model.load_state_dict(torch.load('model.pt'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CbNtwLJBWXId","colab_type":"code","colab":{}},"cell_type":"code","source":["model_save_name = 'model.pt'\n","path = F\"/content/gdrive/My Drive/{model_save_name}\" \n","torch.save(model.state_dict(), path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wbxdMKPtWddZ","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}